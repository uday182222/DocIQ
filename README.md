# DOC-IQ: Intelligent Document Processing Pipeline

DOC-IQ is a comprehensive document processing system that uses OCR and AI to extract structured data from various document types including resumes, driver's licenses, and receipts. Built with a modular, config-driven architecture for easy extensibility.

## ğŸš€ Features

### Document Types Supported
- **Resumes**: Extract FullName, Email, PhoneNumber, Skills, WorkExperience, Education
- **Driver's Licenses**: Extract Name, DateOfBirth, LicenseNumber, IssuingState, ExpiryDate
- **Receipts**: Extract StoreName, LineItems, TotalAmount, PaymentMethod, and more with discrepancy detection

### Key Capabilities
- **OCR Processing**: Uses EasyOCR for robust text extraction
- **AI-Powered Parsing**: OpenAI GPT-4o-mini for intelligent field extraction
- **Config-Driven Architecture**: Easy to add new document types
- **Validation Logic**: Built-in validation with discrepancy detection
- **Batch Processing**: Process multiple documents efficiently
- **CLI Interface**: Easy-to-use command-line tools
- **API Ready**: FastAPI backend for web integration
- **Comprehensive Testing**: Automated testing for all document types

## ğŸ“ Project Structure

```
DOC-IQ/
â”œâ”€â”€ doc_pipeline/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ generic_pipeline.py    # Main processing pipeline (config-driven)
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Configuration package
â”‚   â”‚   â””â”€â”€ doc_config.py          # Document type configurations
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ llm_client.py          # OpenAI integration
â”‚   â”œâ”€â”€ prompts/                   # AI prompts for each document type
â”‚   â”‚   â”œâ”€â”€ resume_extraction.txt
â”‚   â”‚   â”œâ”€â”€ license_extraction.txt
â”‚   â”‚   â””â”€â”€ receipt_extraction.txt
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â””â”€â”€ ocr_engine.py          # OCR processing engine
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ validators.py          # Data validation logic
â”‚   â”‚   â””â”€â”€ file_utils.py          # File handling utilities
â”‚   â”œâ”€â”€ cli.py                     # Command-line interface
â”‚   â””â”€â”€ main.py                    # FastAPI server
â”œâ”€â”€ test/                          # Test scripts and outputs
â”‚   â”œâ”€â”€ output/                    # Processed results
â”‚   â”œâ”€â”€ resumes/                   # Resume test data
â”‚   â”œâ”€â”€ driving_license/           # License test data
â”‚   â””â”€â”€ shop_receipts/             # Receipt test data
â”œâ”€â”€ test_*.py                      # Individual test scripts
â”œâ”€â”€ test_parser.py                 # Comprehensive config test
â”œâ”€â”€ test_doc_config.py             # Configuration module test
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸ›  Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd DOC-IQ
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up OpenAI API key**
   ```bash
   export OPENAI_API_KEY="your-api-key-here"
   ```

## ğŸ“– Usage

### Command Line Interface

**Process a single document:**
```bash
python doc_pipeline/cli.py --mode resume --input path/to/resume.jpg --output test/output/resume
```

**Process a directory of documents:**
```bash
python doc_pipeline/cli.py --mode receipt --input doc_pipeline/data/shop_receipts --output test/output/shop_receipts
```

### Supported Modes
- `resume` - Extract resume information
- `license` - Extract driver's license information  
- `receipt` - Extract receipt information with discrepancy detection

### API Usage

**Start the FastAPI server:**
```bash
cd doc_pipeline
uvicorn main:app --reload
```

**Upload and process a document:**
```bash
curl -X POST "http://localhost:8000/upload" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@path/to/document.jpg" \
     -F "doc_type=resume"
```

## ğŸ§ª Testing

### Comprehensive Configuration Test
Test all document types with mock data:
```bash
python test_parser.py
```

### Individual Document Type Tests
```bash
# Test resume parser
python test_resume_parser.py

# Test license parser  
python test_license_parser.py

# Test receipt parser
python test_receipt_parser.py

# Test configuration module
python test_doc_config.py
```

### Test Results
- **Configuration Test**: 100% success rate (3/3 document types)
- **Resume Processing**: 100% success rate (31/31 files)
- **License Processing**: 82% success rate (9/11 files)
- **Receipt Processing**: 100% success rate (22/22 files)

## ğŸ“Š Results

### Resume Processing
- **Success Rate**: 100% (31/31 files processed)
- **Fields Extracted**: FullName, Email, PhoneNumber, Skills, WorkExperience, Education
- **Output Format**: Structured JSON with validation

### Driver's License Processing
- **Success Rate**: 82% (9/11 files processed)
- **Fields Extracted**: Name, DateOfBirth, LicenseNumber, IssuingState, ExpiryDate
- **Special Features**: Strict name extraction from numbered fields
- **Output Format**: Validated JSON with required field enforcement

### Receipt Processing
- **Success Rate**: 100% (22/22 files processed)
- **Fields Extracted**: StoreName, LineItems, TotalAmount, PaymentMethod, CardLast4Digits
- **Special Features**: Discrepancy detection with 2% tolerance
- **Output Format**: Unified JSON format with comprehensive validation

## ğŸ§© Onboarding a New Document Type in 5 Minutes

Want to add a new document type? Follow these quick steps:

- **1. Add a Prompt:**
  - Create a new prompt file in `doc_pipeline/prompts/`, e.g. `mydoc_extraction.txt`.
  - Write clear instructions and specify the fields you want to extract.

- **2. Register in Config:**
  - Open `doc_pipeline/config/doc_config.py`.
  - Add a new entry to the `DOCUMENT_CONFIGS` dictionary for your document type:
    ```python
    "mydoc": {
        "required_fields": ["Field1", "Field2"],
        "optional_fields": ["Field3"],
        "prompt_path": "doc_pipeline/prompts/mydoc_extraction.txt",
        "validator_fn": your_validator_function,  # Optional, see below
        "postprocess_fn": your_postprocess_function  # Optional, see below
    }
    ```

- **3. (Optional) Add Validator/Postprocessor:**
  - For custom validation or postprocessing, define functions in `doc_config.py` and reference them in your config entry.
  - If not needed, you can reuse existing ones or use simple pass-through functions.

- **4. Run the CLI or API:**
  - Use your new document type with the CLI or API:
    ```bash
    python doc_pipeline/cli.py --mode mydoc --input path/to/file --output path/to/output
    ```
    Or via the API: set `doc_type` to `mydoc` in your request.

That's it! Your new document type is now supported end-to-end.

## ğŸ”§ Technical Details

### Config-Driven Architecture
- **Document Configuration**: Centralized in `doc_pipeline/config/doc_config.py`
- **Dynamic Loading**: Prompts, validators, and postprocessors loaded at runtime
- **Type Safety**: Comprehensive validation for all document types
- **Extensibility**: Easy to add new document types without code changes

### OCR Engine
- **Engine**: EasyOCR with CPU optimization
- **Languages**: English (configurable for multi-language support)
- **Preprocessing**: Automatic image enhancement and noise reduction

### AI Integration
- **Model**: OpenAI GPT-4o-mini
- **Temperature**: 0.0 (deterministic output)
- **Max Tokens**: 2048
- **Prompt Engineering**: Specialized prompts for each document type

### Validation Logic
- **Required Fields**: Enforced per document type
- **Data Types**: Automatic type conversion and validation
- **Discrepancy Detection**: Mathematical validation for receipts
- **Error Handling**: Graceful failure with detailed error messages

## ğŸ“ˆ Performance Metrics

| Document Type | Files Processed | Success Rate | Avg Processing Time |
|---------------|----------------|--------------|-------------------|
| Resumes       | 31             | 100%         | ~15 seconds       |
| Licenses      | 11             | 82%          | ~12 seconds       |
| Receipts      | 22             | 100%         | ~18 seconds       |

## ğŸš¨ Discrepancy Detection

The receipt parser includes intelligent discrepancy detection:
- **Tolerance**: 2% difference threshold
- **Detection**: Automatically flags when sum of items â‰  total amount
- **Warnings**: Logged but don't fail validation
- **Use Cases**: Helps identify OCR errors or missing items

## ğŸ”’ Security & Privacy

- **API Keys**: Environment variable based configuration
- **Data Processing**: Local OCR processing, secure API calls
- **Output**: Structured JSON without sensitive data exposure
- **Validation**: Input sanitization and type checking

## ğŸ›  Development

### Adding New Document Types

1. Create a new prompt file in `doc_pipeline/prompts/`
2. Add configuration entry in `doc_pipeline/config/doc_config.py`
3. (Optional) Create custom validator/postprocessor functions
4. Test with `python test_parser.py`
5. Update CLI interface if needed

### Customizing Prompts

Edit the prompt files in `doc_pipeline/prompts/` to:
- Change field extraction logic
- Add new fields
- Modify validation rules
- Improve accuracy for specific document types

### Testing New Document Types

```bash
# Test configuration loading
python test_doc_config.py

# Test end-to-end processing
python test_parser.py

# Test individual document type
python test_parser.py --doc_type your_new_type
```

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests using the existing test framework
5. Submit a pull request

## ğŸ“ Support

For questions or issues:
- Create an issue in the repository
- Check the test scripts for examples
- Review the configuration guide for adding new document types

## ğŸ¯ Roadmap

- [ ] Multi-language OCR support
- [ ] Additional document types (invoices, contracts, forms)
- [ ] Web-based UI for document upload and processing
- [ ] Real-time processing with WebSocket support
- [ ] Advanced discrepancy detection algorithms
- [ ] Machine learning model fine-tuning capabilities 